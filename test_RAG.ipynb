{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e472a09f",
   "metadata": {},
   "source": [
    "# ğŸš€ Super Hybrid \"Agentic\" RAG (Upgraded)\n",
    "\n",
    "PhiÃªn báº£n nÃ y Ä‘Ã£ Ä‘Æ°á»£c nÃ¢ng cáº¥p dá»±a trÃªn cÃ¡c tiÃªu chuáº©n **Production** thá»±c táº¿, kháº¯c phá»¥c cÃ¡c Ä‘iá»ƒm yáº¿u cá»§a báº£n demo trÆ°á»›c:\n",
    "\n",
    "### ğŸŒŸ CÃ¡c NÃ¢ng Cáº¥p ÄÃ¡ng GiÃ¡ (Production-Grade):\n",
    "1.  **True Agentic Layer (Query Rewriting):** Bá»• sung bÆ°á»›c \"suy luáº­n\" chá»‰nh sá»­a cÃ¢u há»i cá»§a user trÆ°á»›c khi tÃ¬m kiáº¿m, giÃºp search chÃ­nh xÃ¡c hÆ¡n vá»›i cÃ¡c cÃ¢u há»i tá»‘i nghÄ©a.\n",
    "2.  **SOTA Reranker (Multilingual):** Chuyá»ƒn sang dÃ¹ng **`BAAI/bge-reranker-v2-m3`**, model rerank tá»‘t nháº¥t hiá»‡n nay cho Ä‘a ngÃ´n ngá»¯ (bao gá»“m tiáº¿ng Viá»‡t), thay vÃ¬ model tiáº¿ng Anh cÅ©.\n",
    "3.  **Robust Fusion (RRF):** Sá»­ dá»¥ng thuáº­t toÃ¡n **Reciprocal Rank Fusion** Ä‘á»ƒ gá»™p káº¿t quáº£ tá»« Vector vÃ  Keyword. KhÃ´ng cÃ²n phá»¥ thuá»™c vÃ o viá»‡c \"cÃ¢n Ä‘o Ä‘ong Ä‘áº¿m\" trá»ng sá»‘ alpha (0.5 hay 0.7) ná»¯a.\n",
    "4.  **Scalar Quantization (Super Fast):** Ãp dá»¥ng ká»¹ thuáº­t nÃ©n vector (INT8) vÃ  Rescore giá»‘ng `rag_bq` Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ tÃ¬m kiáº¿m vectors lÃªn gáº¥p nhiá»u láº§n.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a1d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "!pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install langchain langchain-community langchain-openai qdrant-client rank_bm25 sentence-transformers openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0caeae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API Key:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API Key configured!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "# Setting up OpenAI API Key\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "print(\"âœ… API Key configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3036f0c5",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion & Processing\n",
    "Load vÃ  chunking dá»¯ liá»‡u `faq_vneid.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3344d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quocanh/.venvs/jupyter/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded chunks: 207\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 1. Load Data\n",
    "file_path = \"faq_vneid.txt\"\n",
    "loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "raw_documents = loader.load()\n",
    "\n",
    "# 2. Chunking Strategy\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "print(f\"âœ… Loaded chunks: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c9e29",
   "metadata": {},
   "source": [
    "## 2. Agentic Layer: Query Rewriting\n",
    "TrÆ°á»›c khi search, Agent sáº½ \"suy nghÄ©\" Ä‘á»ƒ viáº¿t láº¡i cÃ¢u há»i sao cho tá»‘i Æ°u nháº¥t cho search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652fd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def rewrite_query(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Sá»­ dá»¥ng LLM Ä‘á»ƒ viáº¿t láº¡i cÃ¢u há»i cá»§a user thÃ nh má»™t query search chuáº©n.\n",
    "    Loáº¡i bá» cÃ¡c tá»« thá»«a, táº­p trung vÃ o keyword vÃ  ngá»¯ cáº£nh.\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    Báº¡n lÃ  má»™t chuyÃªn gia tá»‘i Æ°u hÃ³a tÃ¬m kiáº¿m (SEO) cho há»‡ thá»‘ng RAG vá» VNeID.\n",
    "    Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  viáº¿t láº¡i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng thÃ nh má»™t cÃ¢u truy váº¥n tÃ¬m kiáº¿m ngáº¯n gá»n, sÃºc tÃ­ch vÃ  chá»©a nhiá»u tá»« khÃ³a quan trá»ng.\n",
    "    Giá»¯ nguyÃªn Ã½ nghÄ©a, chá»‰ thay Ä‘á»•i cáº¥u trÃºc Ä‘á»ƒ dá»… tÃ¬m kiáº¿m hÆ¡n.\n",
    "    KHÃ”NG TRáº¢ Lá»œI CÃ‚U Há»I. CHá»ˆ VIáº¾T Láº I QUERY.\n",
    "    VÃ­ dá»¥:\n",
    "    - User: \"cÃ¡i app nÃ y Ä‘Äƒng nháº­p khÃ´ng Ä‘Æ°á»£c, nÃ³ bÃ¡o lá»—i tÃ¹m lum tÃ  la\"\n",
    "    - Rewrite: \"lá»—i khÃ´ng Ä‘Äƒng nháº­p Ä‘Æ°á»£c á»©ng dá»¥ng VNeID\"\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\", # Hoáº·c model nhá» hÆ¡n nhÆ° gpt-3.5-turbo Ä‘á»ƒ tiáº¿t kiá»‡m/nhanh\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    \n",
    "    rewritten = response.choices[0].message.content.strip()\n",
    "    print(f\"ğŸ”„ Transformed: '{user_query}' -> '{rewritten}'\")\n",
    "    return rewritten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b28c2",
   "metadata": {},
   "source": [
    "## 3. Core Engine: Hybrid Search (RRF) + SOTA Reranker + Quantization\n",
    "NÃ¢ng cáº¥p: \n",
    "- **Reranker**: `BAAI/bge-reranker-v2-m3` (Há»— trá»£ tiáº¿ng Viá»‡t cá»±c tá»‘t).\n",
    "- **Fusion**: RRF (Reciprocal Rank Fusion) thay vÃ¬ Weighted Sum.\n",
    "- **Quantization**: Cáº¥u hÃ¬nh Scalar Quantization (INT8) cho Collection Ä‘á»ƒ giáº£m bá»™ nhá»› vÃ  tÄƒng tá»‘c Ä‘á»™ search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10568913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from qdrant_client import QdrantClient, models\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "class SuperRAG_v2:\n",
    "    def __init__(self, \n",
    "                 embedding_model_name=\"text-embedding-3-large\",\n",
    "                 rerank_model_name=\"BAAI/bge-reranker-v2-m3\", \n",
    "                 collection_name=\"super_rag_v2_quantized\"):\n",
    "        \n",
    "        # 1. Initialize Embeddings\n",
    "        self.embeddings = OpenAIEmbeddings(model=embedding_model_name)\n",
    "        \n",
    "        # 2. Vector DB (Qdrant In-Memory)\n",
    "        self.client = QdrantClient(\":memory:\")\n",
    "        self.collection_name = collection_name\n",
    "        self.vector_size = 3072 if \"large\" in embedding_model_name else 1536\n",
    "        \n",
    "        # Check vÃ  táº¡o collection vá»›i Quantization Config\n",
    "        if not self.client.collection_exists(self.collection_name):\n",
    "             self.client.create_collection(\n",
    "                collection_name=self.collection_name,\n",
    "                vectors_config=models.VectorParams(size=self.vector_size, distance=models.Distance.COSINE),\n",
    "                # UPGRADE: ThÃªm Scalar Quantization Ä‘á»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™ search (nhÆ° rag_bq)\n",
    "                quantization_config=models.ScalarQuantization(\n",
    "                    scalar=models.ScalarQuantizationConfig(\n",
    "                        type=models.ScalarType.INT8,\n",
    "                        quantile=0.99,\n",
    "                        always_ram=True\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # 3. Reranker Upgrade (COMMENTED OUT FOR SPEED)\n",
    "        # print(f\"â³ Loading SOTA Reranker: {rerank_model_name}...\")\n",
    "        # self.reranker = CrossEncoder(rerank_model_name)\n",
    "        # print(\"âœ… Reranker Loaded!\")\n",
    "        self.reranker = None \n",
    "        \n",
    "        self.bm25 = None\n",
    "        self.documents = []\n",
    "\n",
    "    def index_data(self, docs: List[Document]):\n",
    "        print(\"â³ Starting Indexing...\")\n",
    "        self.documents = docs\n",
    "        texts = [doc.page_content for doc in docs]\n",
    "        \n",
    "        # A. Sparse Indexing (BM25)\n",
    "        tokenized_corpus = [text.lower().split() for text in texts]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        print(\"âœ… BM25 Sparse Index Created\")\n",
    "\n",
    "        # B. Dense Indexing (Qdrant)\n",
    "        batch_size = 50\n",
    "        for i in range(0, len(docs), batch_size):\n",
    "            batch_docs = docs[i : i + batch_size]\n",
    "            batch_texts = [d.page_content for d in batch_docs]\n",
    "            vectors = self.embeddings.embed_documents(batch_texts)\n",
    "            \n",
    "            points = [\n",
    "                models.PointStruct(\n",
    "                    id=i + idx,\n",
    "                    vector=vector,\n",
    "                    payload={\"page_content\": text, **d.metadata}\n",
    "                )\n",
    "                for idx, (text, vector, d) in enumerate(zip(batch_texts, vectors, batch_docs))\n",
    "            ]\n",
    "            self.client.upsert(collection_name=self.collection_name, points=points)\n",
    "            \n",
    "        print(f\"âœ… Vector Index Created ({len(docs)} documents)\")\n",
    "\n",
    "    def hybrid_search_rrf(self, query: str, top_k: int = 5, k_rrf: int = 60) -> List[Dict]:\n",
    "        # 1. Sparse Search (BM25)\n",
    "        tokenized_query = query.lower().split()\n",
    "        bm25_indices = np.argsort(self.bm25.get_scores(tokenized_query))[::-1][:50]\n",
    "        \n",
    "        # 2. Dense Search (Vector)\n",
    "        query_vector = self.embeddings.embed_query(query)\n",
    "        \n",
    "        # FIX: DÃ¹ng query_points vÃ  thÃªm cáº¥u hÃ¬nh SearchParams (Quantization) Ä‘á»ƒ search siÃªu tá»‘c\n",
    "        search_result = self.client.query_points(\n",
    "            collection_name=self.collection_name,\n",
    "            query=query_vector,\n",
    "            limit=50,\n",
    "            # UPGRADE: Search vá»›i Quantization Search Params (nhÆ° rag_bq)\n",
    "            search_params=models.SearchParams(\n",
    "                quantization=models.QuantizationSearchParams(\n",
    "                    ignore=False,\n",
    "                    rescore=True,\n",
    "                    oversampling=2.0,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        vector_results = search_result.points \n",
    "        \n",
    "        # 3. RRF Fusion\n",
    "        doc_scores = {}\n",
    "        for rank, res in enumerate(vector_results):\n",
    "            idx = res.id\n",
    "            if idx not in doc_scores:\n",
    "                doc_scores[idx] = 0.0\n",
    "            doc_scores[idx] += 1 / (k_rrf + rank + 1)\n",
    "            \n",
    "        for rank, idx in enumerate(bm25_indices):\n",
    "            if idx not in doc_scores:\n",
    "                doc_scores[idx] = 0.0\n",
    "            doc_scores[idx] += 1 / (k_rrf + rank + 1)\n",
    "            \n",
    "        sorted_doc_ids = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        candidates = []\n",
    "        for idx, score in sorted_doc_ids[:20]: \n",
    "            candidates.append({\n",
    "                \"doc\": self.documents[idx],\n",
    "                \"rrf_score\": score,\n",
    "                \"rerank_score\": score # Táº¡m gÃ¡n rerank_score báº±ng rrf_score vÃ¬ bá» qua bÆ°á»›c rerank\n",
    "            })\n",
    "            \n",
    "        return candidates\n",
    "\n",
    "    def search(self, query: str, top_k: int = 5) -> List[Dict]:\n",
    "        candidates = self.hybrid_search_rrf(query)\n",
    "        if not candidates:\n",
    "            return []\n",
    "            \n",
    "        # COMMENTED OUT RERANKING FOR SPEED\n",
    "        if self.reranker:\n",
    "            doc_texts = [c[\"doc\"].page_content for c in candidates]\n",
    "            pairs = [[query, doc_text] for doc_text in doc_texts]\n",
    "            \n",
    "            rerank_scores = self.reranker.predict(pairs)\n",
    "            \n",
    "            for i, candidate in enumerate(candidates):\n",
    "                candidate[\"rerank_score\"] = float(rerank_scores[i])\n",
    "                \n",
    "            candidates.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "        \n",
    "        return candidates[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ae57dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Starting Indexing...\n",
      "âœ… BM25 Sparse Index Created\n",
      "âœ… Vector Index Created (207 documents)\n"
     ]
    }
   ],
   "source": [
    "# Khá»Ÿi táº¡o há»‡ thá»‘ng má»›i\n",
    "rag_system = SuperRAG_v2()\n",
    "rag_system.index_data(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba9501",
   "metadata": {},
   "source": [
    "## 4. Test & Demo (End-to-End Flow)\n",
    "Cháº¡y thá»­ vá»›i quy trÃ¬nh hoÃ n chá»‰nh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319fc1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¬ User: táº¡i sao Ä‘Äƒng nháº­p trÃªn thiáº¿t bá»‹ má»›i nÃ³ báº¯t nháº­p mÃ£ xÃ¡c nháº­n láº±ng nháº±ng váº­y\n",
      "ğŸ”„ Transformed: 'táº¡i sao Ä‘Äƒng nháº­p trÃªn thiáº¿t bá»‹ má»›i nÃ³ báº¯t nháº­p mÃ£ xÃ¡c nháº­n láº±ng nháº±ng váº­y' -> 'Ä‘Äƒng nháº­p thiáº¿t bá»‹ má»›i VNeID yÃªu cáº§u nháº­p mÃ£ xÃ¡c nháº­n phá»©c táº¡p'\n",
      "â±ï¸ Search Time: 3.4885s\n",
      "\n",
      "ğŸ” Top Contexts found:\n",
      "   [1] Score: 0.03 | ...Sau khi xÃ¡c nháº­n thÃ nh cÃ´ng, thiáº¿t bá»‹ cÅ© sáº½ khÃ´ng cÃ²n truy cáº­p Ä‘Æ°á»£c vÃ o tÃ i khoáº£n VNeID ná»¯a áº¡. 3. TÃ´...\n",
      "   [2] Score: 0.03 | ...Sau Ä‘Ã³ nháº­p OTP nÃ y vÃ o thiáº¿t bá»‹ B Ä‘á»ƒ hoÃ n táº¥t Ä‘Äƒng nháº­p.  Hoáº·c anh/chá»‹ cÃ³ thá»ƒ chá»n â€œBá» quaâ€ Ä‘á»ƒ Ä‘Ã³ng...\n",
      "   [3] Score: 0.03 | ...19. Táº¡i sao há»‡ thá»‘ng bÃ¡o tháº» CCCD Ä‘Ã£ háº¿t háº¡n khi Ä‘Äƒng nháº­p? Dáº¡, Ä‘Ã³ lÃ  khi ngÃ y háº¿t háº¡n tháº» CCCD cá»§a ...\n",
      "\n",
      "ğŸ¤– Bot: Khi Ä‘Äƒng nháº­p trÃªn thiáº¿t bá»‹ má»›i, há»‡ thá»‘ng yÃªu cáº§u nháº­p mÃ£ xÃ¡c nháº­n (OTP) nháº±m Ä‘áº£m báº£o an toÃ n cho tÃ i khoáº£n cá»§a anh/chá»‹. ÄÃ¢y lÃ  quy Ä‘á»‹nh báº£o máº­t Ä‘á»ƒ xÃ¡c thá»±c ráº±ng chÃ­nh chá»§ má»›i Ä‘Æ°á»£c phÃ©p truy cáº­p tÃ i khoáº£n trÃªn thiáº¿t bá»‹ chÆ°a tá»«ng Ä‘Äƒng nháº­p trÆ°á»›c Ä‘Ã³. MÃ£ OTP sáº½ Ä‘Æ°á»£c gá»­i vá» sá»‘ Ä‘iá»‡n thoáº¡i Ä‘Ã£ Ä‘Äƒng kÃ½ hoáº·c hiá»ƒn thá»‹ trong á»©ng dá»¥ng VNeID trÃªn thiáº¿t bá»‹ cÅ© (thiáº¿t bá»‹ Ä‘Ã£ kÃ­ch hoáº¡t trÆ°á»›c Ä‘Ã³). Viá»‡c nÃ y giÃºp ngÄƒn cháº·n truy cáº­p trÃ¡i phÃ©p vÃ  báº£o vá»‡ thÃ´ng tin cÃ¡ nhÃ¢n cá»§a anh/chá»‹. Sau khi Ä‘Äƒng nháº­p thÃ nh cÃ´ng trÃªn thiáº¿t bá»‹ má»›i, thiáº¿t bá»‹ cÅ© sáº½ bá»‹ Ä‘Äƒng xuáº¥t vÃ  yÃªu cáº§u Ä‘á»•i máº­t kháº©u Ä‘á»ƒ tÄƒng cÆ°á»ng báº£o máº­t. VÃ¬ váº­y, dÃ¹ cÃ³ thá»ƒ cáº£m tháº¥y láº±ng nháº±ng, nhÆ°ng quy trÃ¬nh nÃ y ráº¥t cáº§n thiáº¿t Ä‘á»ƒ báº£o vá»‡ tÃ i khoáº£n cá»§a anh/chá»‹.\n",
      "========================================\n",
      "\n",
      "ğŸ’¬ User: lÃ m máº¥t cÃ¡i máº­t kháº©u cá»§a app rá»“i giá» sao?\n",
      "ğŸ”„ Transformed: 'lÃ m máº¥t cÃ¡i máº­t kháº©u cá»§a app rá»“i giá» sao?' -> 'cÃ¡ch láº¥y láº¡i máº­t kháº©u á»©ng dá»¥ng VNeID khi bá»‹ máº¥t'\n",
      "â±ï¸ Search Time: 1.0747s\n",
      "\n",
      "ğŸ” Top Contexts found:\n",
      "   [1] Score: 0.03 | ...XÃ¡c thá»±c OTP xong, anh/chá»‹ táº¡o máº­t kháº©u má»›i, rá»“i dÃ¹ng máº­t kháº©u nÃ y Ä‘á»ƒ Ä‘Äƒng nháº­p láº¡i.   LÆ°u Ã½ vá» máº­t ...\n",
      "   [2] Score: 0.03 | ...Sau khi xÃ¡c nháº­n thÃ nh cÃ´ng, thiáº¿t bá»‹ cÅ© sáº½ khÃ´ng cÃ²n truy cáº­p Ä‘Æ°á»£c vÃ o tÃ i khoáº£n VNeID ná»¯a áº¡. 3. TÃ´...\n",
      "   [3] Score: 0.03 | ...XÃ¡c thá»±c OTP xong, anh/chá»‹ táº¡o máº­t kháº©u má»›i, rá»“i dÃ¹ng máº­t kháº©u nÃ y Ä‘á»ƒ Ä‘Äƒng nháº­p láº¡i.   LÆ°u Ã½ vá» máº­t ...\n",
      "\n",
      "ğŸ¤– Bot: Náº¿u anh/chá»‹ lÃ m máº¥t máº­t kháº©u cá»§a app VNeID, anh/chá»‹ cÃ³ thá»ƒ láº¥y láº¡i máº­t kháº©u má»›i báº±ng cÃ¡ch sau:\n",
      "\n",
      "1. Má»Ÿ á»©ng dá»¥ng VNeID vÃ  chá»n \"QuÃªn máº­t kháº©u\".\n",
      "2. Nháº­p sá»‘ Ä‘á»‹nh danh cÃ¡ nhÃ¢n (sá»‘ CCCD) vÃ  sá»‘ Ä‘iá»‡n thoáº¡i Ä‘Ã£ Ä‘Äƒng kÃ½ VNeID, sau Ä‘Ã³ chá»n \"Nháº­p thÃ´ng tin xÃ¡c thá»±c\" vÃ  gá»­i yÃªu cáº§u.\n",
      "3. Nháº­p Ä‘áº§y Ä‘á»§ vÃ  chÃ­nh xÃ¡c cÃ¡c thÃ´ng tin há»‡ thá»‘ng yÃªu cáº§u nhÆ°:\n",
      "   - Sá»‘ Ä‘á»‹nh danh cÃ¡ nhÃ¢n\n",
      "   - Sá»‘ Ä‘iá»‡n thoáº¡i\n",
      "   - Há» vÃ  tÃªn khai sinh\n",
      "   - NgÃ y thÃ¡ng nÄƒm sinh\n",
      "   - (Náº¿u Ä‘Æ°á»£c yÃªu cáº§u) NgÃ y cáº¥p CCCD\n",
      "4. Nháº­p mÃ£ OTP Ä‘Æ°á»£c gá»­i vá» sá»‘ Ä‘iá»‡n thoáº¡i Ä‘Ã£ Ä‘Äƒng kÃ½.\n",
      "5. Thiáº¿t láº­p máº­t kháº©u má»›i theo yÃªu cáº§u:\n",
      "   - Tá»« 8â€“20 kÃ½ tá»±\n",
      "   - CÃ³ chá»¯ thÆ°á»ng, chá»¯ in hoa, chá»¯ sá»‘\n",
      "   - Ãt nháº¥t 1 kÃ½ tá»± Ä‘áº·c biá»‡t\n",
      "6. XÃ¡c nháº­n Ä‘á»ƒ hoÃ n táº¥t.\n",
      "\n",
      "Sau khi xÃ¡c thá»±c OTP vÃ  táº¡o máº­t kháº©u má»›i thÃ nh cÃ´ng, anh/chá»‹ dÃ¹ng máº­t kháº©u nÃ y Ä‘á»ƒ Ä‘Äƒng nháº­p láº¡i vÃ o á»©ng dá»¥ng VNeID.\n",
      "\n",
      "Náº¿u anh/chá»‹ bá»‹ máº¥t Ä‘iá»‡n thoáº¡i vÃ  quÃªn máº­t kháº©u nhÆ°ng váº«n cÃ²n dÃ¹ng sá»‘ Ä‘iá»‡n thoáº¡i Ä‘Ã£ Ä‘Äƒng kÃ½, cÃ³ thá»ƒ thá»±c hiá»‡n cÃ¡c bÆ°á»›c trÃªn Ä‘á»ƒ láº¥y láº¡i máº­t kháº©u vÃ  Ä‘Äƒng nháº­p trÃªn thiáº¿t bá»‹ má»›i. Náº¿u máº¥t sá»‘ Ä‘iá»‡n thoáº¡i, anh/chá»‹ cáº§n liÃªn há»‡ nhÃ  máº¡ng Ä‘á»ƒ khÃ´i phá»¥c sá»‘ trÆ°á»›c khi thá»±c hiá»‡n cÃ¡c bÆ°á»›c trÃªn.\n",
      "\n",
      "ChÃºc anh/chá»‹ thÃ nh cÃ´ng!\n",
      "========================================\n",
      "\n",
      "ğŸ’¬ User: cÃ¡ch Ä‘Äƒng kÃ½ tÃ i khoáº£n vneid má»©c 2\n",
      "ğŸ”„ Transformed: 'cÃ¡ch Ä‘Äƒng kÃ½ tÃ i khoáº£n vneid má»©c 2' -> 'Ä‘Äƒng kÃ½ tÃ i khoáº£n VNeID má»©c 2 hÆ°á»›ng dáº«n chi tiáº¿t'\n",
      "â±ï¸ Search Time: 1.3115s\n",
      "\n",
      "ğŸ” Top Contexts found:\n",
      "   [1] Score: 0.03 | ...BÆ°á»›c 1: CÃ´ng dÃ¢n má»Ÿ App Store trÃªn thiáº¿t bá»‹ di Ä‘á»™ng. BÆ°á»›c 2: Táº¡i má»¥c TÃ¬m kiáº¿m, cÃ´ng dÃ¢n nháº­p tá»« khÃ³a...\n",
      "   [2] Score: 0.03 | ...2.  HÆ°á»›ng dáº«n Ä‘Äƒng kÃ½ tÃ i khoáº£n má»©c 1 Ä‘á»‘i vá»›i thiáº¿t bá»‹ khÃ´ng há»— trá»£ NFC? Dáº¡, Ä‘á»ƒ Ä‘Äƒng kÃ½ tÃ i khoáº£n má»©...\n",
      "   [3] Score: 0.03 | ...5. Táº¡i sao khi báº¥m QuÃªn máº­t kháº©u mÃ  tÃ´i khÃ´ng nháº­n Ä‘Æ°á»£c mÃ£ OTP? Dáº¡, náº¿u anh/chá»‹ chá»n â€œQuÃªn máº­t kháº©uâ€...\n",
      "\n",
      "ğŸ¤– Bot: Hiá»‡n táº¡i trong thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p khÃ´ng cÃ³ hÆ°á»›ng dáº«n cá»¥ thá»ƒ vá» cÃ¡ch Ä‘Äƒng kÃ½ tÃ i khoáº£n VNeID má»©c 2. Náº¿u anh/chá»‹ cáº§n Ä‘Äƒng kÃ½ má»©c 2, anh/chá»‹ cÃ³ thá»ƒ tham kháº£o vÃ  thá»±c hiá»‡n theo hÆ°á»›ng dáº«n Ä‘Äƒng kÃ½ cÃ¡c má»©c tháº¥p hÆ¡n (má»©c 0 vÃ  má»©c 1) trÆ°á»›c, sau Ä‘Ã³ liÃªn há»‡ cÆ¡ quan cÃ´ng an hoáº·c trung tÃ¢m há»— trá»£ VNeID Ä‘á»ƒ Ä‘Æ°á»£c hÆ°á»›ng dáº«n chi tiáº¿t vá» má»©c 2.\n",
      "\n",
      "Náº¿u anh/chá»‹ cáº§n, tÃ´i cÃ³ thá»ƒ há»— trá»£ hÆ°á»›ng dáº«n Ä‘Äƒng kÃ½ tÃ i khoáº£n má»©c 0 hoáº·c má»©c 1. Anh/chá»‹ vui lÃ²ng cho biáº¿t nhÃ©!\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def advanced_rag_chat(user_query: str):\n",
    "    start_time = time.time()\n",
    "    print(f\"\\nğŸ’¬ User: {user_query}\")\n",
    "    \n",
    "    # 1. Rewriting (CÃ³ thá»ƒ táº¯t náº¿u muá»‘n test thuáº§n tá»‘c Ä‘á»™ search)\n",
    "    search_query = rewrite_query(user_query)\n",
    "    \n",
    "    # 2. Retrieval & Rerank\n",
    "    results = rag_system.search(search_query, top_k=3)\n",
    "    \n",
    "    end_search_time = time.time()\n",
    "    print(f\"â±ï¸ Search Time: {end_search_time - start_time:.4f}s\")\n",
    "\n",
    "    print(\"\\nğŸ” Top Contexts found:\")\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"   [{i+1}] Score: {res['rerank_score']:.2f} | ...{res['doc'].page_content[0:100].replace('\\n', ' ')}...\")\n",
    "    \n",
    "    # 3. Generation\n",
    "    context_str = \"\\n\\n---\\n\\n\".join([c[\"doc\"].page_content for c in results])\n",
    "    system_prompt = \"\"\"\n",
    "    Báº¡n lÃ  trá»£ lÃ½ há»— trá»£ VNeID chuyÃªn nghiá»‡p. \n",
    "    HÃ£y tráº£ lá»i dá»±a trÃªn context Ä‘Æ°á»£c cung cáº¥p.\n",
    "    Náº¿u khÃ´ng cÃ³ thÃ´ng tin, hÃ£y thÃ nh tháº­t nÃ³i khÃ´ng biáº¿t.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {user_query}\\n\\nContext:\\n{context_str}\"}\n",
    "        ],\n",
    "        temperature=0.3\n",
    "        # streaming=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ¤– Bot: {response.choices[0].message.content}\\n\" + \"=\"*40)\n",
    "\n",
    "# --- TEST CASES ---\n",
    "test_cases = [\n",
    "    \"táº¡i sao Ä‘Äƒng nháº­p trÃªn thiáº¿t bá»‹ má»›i nÃ³ báº¯t nháº­p mÃ£ xÃ¡c nháº­n láº±ng nháº±ng váº­y\", # CÃ¢u há»i conversational, cáº§n rewrite\n",
    "    \"lÃ m máº¥t cÃ¡i máº­t kháº©u cá»§a app rá»“i giá» sao?\", \n",
    "    \"cÃ¡ch Ä‘Äƒng kÃ½ tÃ i khoáº£n vneid má»©c 2\"\n",
    "]\n",
    "\n",
    "for q in test_cases:\n",
    "    advanced_rag_chat(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
